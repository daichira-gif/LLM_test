{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyNxHOnaRdewDaE0XknBhNSG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daichira-gif/daichira/blob/main/Google_Gemini_%E3%82%AB%E3%83%A1%E3%83%A9%E7%94%BB%E5%83%8F%E3%81%AE%E8%AA%AC%E6%98%8E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- カメラを起動、撮影\n",
        "- 画像の読み込み\n",
        "- 画像に関する質問に回答\n",
        "\n",
        "（参照）<br>\n",
        "https://note.com/astropomeai/n/n6f6ba461d36f <br>\n",
        "https://blog.kikagaku.co.jp/pillow/\n"
      ],
      "metadata": {
        "id": "G2RzUJ8LwEYn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Nxi4W2exe1og",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee8b6d13-664b-459c-cdf9-1307ca65fe35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/146.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m122.9/146.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.9/146.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n"
          ]
        }
      ],
      "source": [
        "# パッケージのインストール\n",
        "!pip install -q -U google-generativeai\n",
        "!pip install pydub\n",
        "!pip install Pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  with open(filename, 'wb') as f:\n",
        "    f.write(binary)\n",
        "  return filename"
      ],
      "metadata": {
        "id": "cos-05M-bLhZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "8cPTMfq_uNS0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#カメラの起動と写真撮影\n",
        "from IPython.display import Image\n",
        "try:\n",
        "  filename = take_photo()\n",
        "  print('Saved to {}'.format(filename))\n",
        "\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "  print(str(err))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CV7uTnTJbR3Y",
        "outputId": "ace6f9e1-888d-41bd-9e19-77043a78c425"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      canvas.width = video.videoWidth;\n",
              "      canvas.height = video.videoHeight;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to photo.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from collections import deque\n",
        "from datetime import datetime\n",
        "from pydub import AudioSegment\n",
        "from pydub.playback import play\n",
        "import google.generativeai as genai\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "\n",
        "def wrap_text(text, line_length):\n",
        "    \"\"\"テキストを指定された長さで改行する\"\"\"\n",
        "    words = text.split(' ')\n",
        "    lines = []\n",
        "    current_line = ''\n",
        "\n",
        "    for word in words:\n",
        "        if len(current_line) + len(word) + 1 > line_length:\n",
        "            lines.append(current_line)\n",
        "            current_line = word\n",
        "        else:\n",
        "            current_line += ' ' + word\n",
        "\n",
        "    lines.append(current_line)  # 最後の行を追加\n",
        "    return lines\n",
        "\n",
        "def add_text_to_frame(frame, text):\n",
        "    # テキストを70文字ごとに改行\n",
        "    wrapped_text = wrap_text(text, 70)\n",
        "\n",
        "    # フレームの高さと幅を取得\n",
        "    height, width = frame.shape[:2]\n",
        "\n",
        "    # テキストのフォントとサイズ\n",
        "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    font_scale = 1.0  # フォントサイズを大きくする\n",
        "    color = (255, 255, 255)  # 白色\n",
        "    outline_color = (0, 0, 0)  # 輪郭の色（黒）\n",
        "    thickness = 2\n",
        "    outline_thickness = 4  # 輪郭の太さ\n",
        "    line_type = cv2.LINE_AA\n",
        "\n",
        "    # 各行のテキストを画像に追加\n",
        "    for i, line in enumerate(wrapped_text):\n",
        "        position = (10, 30 + i * 30)  # 各行の位置を調整（より大きい間隔）\n",
        "\n",
        "        # テキストの輪郭を描画\n",
        "        cv2.putText(frame, line, position, font, font_scale, outline_color, outline_thickness, line_type)\n",
        "\n",
        "        # テキストを描画\n",
        "        cv2.putText(frame, line, position, font, font_scale, color, thickness, line_type)\n",
        "\n",
        "def save_frame(frame, filename, directory='./frames'):\n",
        "    # ディレクトリが存在しない場合は作成\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "    # ファイル名のパスを作成\n",
        "    filepath = os.path.join(directory, filename)\n",
        "    # フレームを保存\n",
        "    cv2.imwrite(filepath, frame)\n",
        "\n",
        "def save_temp_frame(frame, filename, directory='./temp'):\n",
        "    # ディレクトリが存在しない場合は作成\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "    # ファイル名のパスを作成\n",
        "    filepath = os.path.join(directory, filename)\n",
        "    # フレームを保存\n",
        "    cv2.imwrite(filepath, frame)\n",
        "    return filepath  # 保存したファイルのパスを返す\n",
        "\n",
        "def send_frame_with_text_to_gemini(frame, previous_texts, timestamp, user_input, client):\n",
        "\n",
        "    temp_file_path = save_temp_frame(frame, \"temp.jpg\")\n",
        "    img = PIL.Image.open(temp_file_path)\n",
        "\n",
        "    img = np.array(img)\n",
        "\n",
        "\n",
        "    # 過去のテキストをコンテキストとして結合\n",
        "    context = ' '.join(previous_texts)\n",
        "\n",
        "    # Geminiモデルの初期化\n",
        "    model = client.GenerativeModel('gemini-pro-vision')\n",
        "\n",
        "    # モデルに画像とテキストの指示を送信\n",
        "    prompt = f\"Given the context: {context} and the current time: {timestamp}, please respond to the following message in Japanese without repeating the context. Message: {user_input}\"\n",
        "    img = Image.fromarray(frame)\n",
        "    response = model.generate_content([prompt, img], stream=True)\n",
        "    response.resolve()\n",
        "\n",
        "    # 生成されたテキストを返す\n",
        "    return response.text\n",
        "\n"
      ],
      "metadata": {
        "id": "fgV3RQWciBn-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#　モジュールの読み込み\n",
        "from PIL import Image\n",
        "\n",
        "#　画像の読み込み\n",
        "img2 = Image.open('photo.jpg')\n",
        "\n",
        "img2"
      ],
      "metadata": {
        "id": "sECAzZQje2OR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def main():\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    filename = 'photo.jpg'\n",
        "\n",
        "    try:\n",
        "         video = Image.open('photo.jpg')\n",
        "\n",
        "    except IOError as e:\n",
        "        print(f\"エラーが発生しました: {e}\")\n",
        "        return\n",
        "\n",
        "    # 最近の5フレームのテキストを保持するためのキュー\n",
        "    previous_texts = deque(maxlen=5)\n",
        "\n",
        "    while True:\n",
        "\n",
        "        print(\"新しいプロンプトを入力するか、Enterキーを押して続行してください (プログラムを終了するには 'exit' と入力）:\")\n",
        "        user_input = input().strip()  # 入力を受け取る\n",
        "\n",
        "        if user_input == \"exit\":\n",
        "            print(\"了解しました。\")\n",
        "            break\n",
        "\n",
        "        if not user_input:\n",
        "            user_input = \"Tell me what you see.\"\n",
        "\n",
        "        frame = video\n",
        "        frame = np.array(frame)\n",
        "\n",
        "        # 現在のタイムスタンプを取得\n",
        "        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        # geminiにフレームを送信し、生成されたテキストを取得\n",
        "        generated_text = send_frame_with_text_to_gemini(frame, previous_texts, timestamp, user_input, genai)\n",
        "        print(f\"Timestamp: {timestamp}, Generated Text: {generated_text}\")\n",
        "\n",
        "        # タイムスタンプ付きのテキストをキューに追加\n",
        "        previous_texts.append(f\"[{timestamp}] Message: {user_input}, Generated Text: {generated_text}\")\n",
        "\n",
        "        # フレームにテキストを追加(日本語は文字化けします)\n",
        "        text_to_add = f\"{timestamp}: {generated_text}\"\n",
        "\n",
        "        add_text_to_frame(frame, text_to_add)\n",
        "\n",
        "        # フレームを保存\n",
        "        filename = f\"{timestamp}.jpg\"\n",
        "        save_frame(frame, filename)\n",
        "\n",
        "    # ビデオをリリースする\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANafQ7OwVoD2",
        "outputId": "8aab21be-1443-428a-f74a-a10413cea994"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "新しいプロンプトを入力するか、Enterキーを押して続行してください (プログラムを終了するには 'exit' と入力）:\n",
            "exit\n",
            "了解しました。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lz_gKCs9esTc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}